# NLP Enriched News

## Description
Ce projet ex√©cute un pipeline NLP sur 300 articles de presse pour enrichir les donn√©es avec des informations sur les entit√©s nomm√©es, les sujets abord√©s, l'analyse de sentiment et la d√©tection de scandales environnementaux. Les r√©sultats sont sauvegard√©s dans un fichier CSV `results/enhanced_news.csv`.

## Structure des donn√©es g√©n√©r√©es

Chaque article trait√© est enregistr√© avec les informations suivantes :

| Champ               | Type          | Description |
|--------------------|--------------|-------------|
| `uuid`            | `int` ou `str` | Identifiant unique de l'article |
| `url`             | `str` | URL de l'article |
| `date_scraped`    | `date` | Date de r√©cup√©ration de l'article |
| `headline`        | `str` | Titre de l'article |
| `body`            | `str` | Contenu de l'article |
| `organizations`   | `list[str]` | Liste des organisations mentionn√©es dans l'article |
| `topics`          | `list[str]` | Liste des sujets d√©tect√©s dans l'article |
| `sentiment`       | `float` | Score de sentiment de l'article (-1 : n√©gatif, 0 : neutre, 1 : positif) |
| `scandal_distance`| `float` | Score indiquant la probabilit√© d'un scandale environnemental |
| `top_10`          | `bool` | Indique si l'article fait partie des 10 plus susceptibles d'√™tre li√©s √† un scandale |

## Ex√©cution des script

Pour ex√©cuter l'extraction des articles :

```bash
python scrapper.py
```

Pour ex√©cuter le traitement des articles :

```bash
python nlp_enriched_news.py
```

L'ex√©cution affichera des informations d√©taill√©es sur chaque √©tape du pipeline :

```
Enriching <URL>:

Cleaning document ... (optional)

---------- Detect entities ----------
Detected <X> companies which are <company_1> and <company_2>

---------- Topic detection ----------
Text preprocessing ...
The topic of the article is: <topic>

---------- Sentiment analysis ----------
Text preprocessing ... (optional)
The article <title> has a <sentiment> sentiment

---------- Scandal detection ----------
Computing embeddings and distance ...
Environmental scandal detected for <entity>
```

## Explication des choix m√©thodologiques

### Mod√®le d'Embeddings
Nous utilisons le mod√®le **`fr_core_news_md`** de SpaCy, un mod√®le de taille interm√©diaire contenant des repr√©sentations vectorielles pour les mots en fran√ßais. Ce mod√®le a √©t√© choisi car :
- Il offre un bon √©quilibre entre pr√©cision et performance.
- Il fournit des embeddings de mots pr√©-entra√Æn√©s utiles pour la d√©tection de similarit√© s√©mantique.
- Il int√®gre une reconnaissance des entit√©s nomm√©es efficace pour extraire les organisations cit√©es.

### Distance de Similarit√©
Nous avons opt√© pour **la similarit√© cosinus** pour comparer les phrases avec les mots-cl√©s li√©s aux scandales environnementaux. Ce choix repose sur les raisons suivantes :
- La similarit√© cosinus est particuli√®rement efficace pour mesurer la proximit√© s√©mantique entre des vecteurs de mots ou de phrases.
- Elle est ind√©pendante de la longueur des phrases et est couramment utilis√©e en NLP.
- Elle permet d'√©valuer √† quel point une phrase d'un article est proche des concepts de scandale environnemental.

### D√©tection de Scandale
Pour identifier les articles li√©s √† des scandales environnementaux, nous :
1. Extrayons les organisations mentionn√©es.
2. S√©lectionnons les phrases contenant ces organisations.
3. Comparons leurs embeddings avec ceux des mots-cl√©s li√©s aux scandales environnementaux.
4. Calculons un score bas√© sur la similarit√© cosinus.
5. Classons les articles et s√©lectionnons les 10 les plus pertinents.

### Analyse de Sentiment
Nous utilisons **VADER (SentimentIntensityAnalyzer de NLTK)** pour classifier les articles en `positif`, `neutre` ou `n√©gatif`. Ce choix est motiv√© par :
- Son efficacit√© pour analyser le ton des textes courts et informatifs.
- Sa capacit√© √† g√©rer les nuances gr√¢ce √† un score `compound` permettant une classification fine.

### D√©tection de Topics
Le mod√®le de d√©tection de sujets est charg√© depuis `data/model/topic_classifier.pkl`. Il contient un vectorizer et un classifier entra√Æn√© sur des articles en fran√ßais. Les sujets d√©tect√©s sont ensuite ajout√©s aux m√©tadonn√©es de chaque article.

## R√©sultat final
Le script g√©n√®re un fichier `enhanced_news.csv` contenant toutes les informations enrichies pour chaque article.

---

Si vous avez des questions ou des suggestions, n'h√©sitez pas √† contribuer ! üöÄ

